#!/usr/bin/python
# coding: utf8
import argparse
import hashlib
import io
import mimetypes
import os.path
import re
import pickledb
import traceback
from datetime import datetime
from PhotoInfo import PhotoInfo

from googleapiclient import http
from googleapiclient.http import MediaFileUpload
from appdirs import AppDirs
from progressbar import (AdaptiveETA, AdaptiveTransferSpeed, Bar, Percentage,
                         ProgressBar)
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive

APPNAME = "gphotos-sync"


###############################################################################
# Useful classes
###############################################################################


class NoGooglePhotosFolderError(Exception):
    pass


class LocalMedia(object):
    CHUNK_SIZE = 4096

    def __init__(self, media_path):
        self.path = media_path

    @property
    def filename(self):
        return os.path.basename(self.path)

    @property
    def canonical_filename(self):
        return self.filename

    @property
    def size(self):
        return os.path.getsize(self.path)

    @classmethod
    def read_chunk(cls, media_file):
        return media_file.read(LocalMedia.CHUNK_SIZE)

    @property
    def checksum(self):
        md5sum = hashlib.md5()
        with io.open(self.path, 'rb') as media_file:
            chunk_reader = self.read_chunk(media_file)
            for chunk in iter(chunk_reader, b""):
                md5sum.update(chunk)

        return md5sum.hexdigest()

    @property
    def mimetype(self):
        mimetype, _ = mimetypes.guess_type(self.path)
        return mimetype


class GooglePhotosMedia(object):
    def __init__(self, drive_file):
        self.drive_file = drive_file
        self.duplicate_number = 0

    def get_custom_property_value(self, key):
        for prop in self.drive_file["properties"]:
            if prop["key"] == key:
                return prop["value"]

        raise KeyError()

    def get_exif_value(self, tag_name):
        try:
            exif_override_property_name = "exif-%s" % tag_name
            return self.get_custom_property_value(exif_override_property_name)
        except KeyError:
            return self.drive_file["imageMediaMetadata"][tag_name]

    @property
    def date(self):
        try:
            exif_date = self.get_exif_value("date")
            photo_date = datetime.strptime(exif_date, "%Y:%m:%d %H:%M:%S")
        except (KeyError, ValueError):
            import_date = self.drive_file["createdDate"]
            # some times are ucase T and non zero millisecs - normalize
            photo_date = datetime.strptime(import_date.upper()[:-4],
                                           "%Y-%m-%dT%H:%M:%S.")

        return photo_date

    @property
    def size(self):
        return int(self.drive_file["fileSize"])

    @property
    def checksum(self):
        return self.drive_file["md5Checksum"]

    @property
    def id(self):
        return self.drive_file["id"]

    @property
    def camera_owner(self):
        try:
            artist = self.get_exif_value("artist")
            match = re.match("Camera Owner, ([^;]+)(?:;|$)", artist)
            camera_owner = match.group(1) if match else artist
        except KeyError:
            camera_owner = None

        return camera_owner

    @property
    def camera_model(self):
        try:
            camera_model = self.get_exif_value("cameraModel")
        except KeyError:
            if re.match(r"IMG-\d{8}-WA\d+", self.filename):
                camera_model = "WhatsApp"
            else:
                camera_model = None

        return camera_model

    @property
    def extension(self):
        try:
            return self.drive_file["fileExtension"]
        except KeyError:
            return ''

    @property
    def description(self):
        try:
            return self.drive_file["description"]
        except KeyError:
            return ''

    @property
    def filename(self):
        base, ext = os.path.splitext(os.path.basename(self.drive_file["title"]))
        if self.duplicate_number > 0:
            return "%(base)s (%(duplicate)d)%(ext)s" % {
                'base': base,
                'ext': ext,
                'duplicate': self.duplicate_number
            }
        else:
            return self.drive_file["title"]


class GooglePhotosSync(object):
    GOOGLE_PHOTO_FOLDER_QUERY = (
        'title = "Google Photos" and "root" in parents and trashed=false')
    MEDIA_QUERY = '"%s" in parents and trashed=false '
    FOLDER_QUERY = ('title = "%s" and "%s" in parents and trashed=false'
                    ' and mimeType="application/vnd.google-apps.folder"')
    AFTER_QUERY = " and modifiedDate >= '%sT00:00:00'"
    BEFORE_QUERY = " and modifiedDate <= '%sT00:00:00'"
    DB_NAME = '.gphotos.db'
    PAGE_SIZE = 100

    def __init__(self, args,
                 client_secret_file="client_secret.json",
                 credentials_json="credentials.json"):

        self.args = args
        self.root_folder = args.root_folder
        self.start_folder = args.start_folder
        self.target_folder = os.path.join(self.root_folder,
                                          self.start_folder)
        if args.new_token:
            os.remove(credentials_json)
        self.g_auth = GoogleAuth()
        self.g_auth.settings["client_config_file"] = client_secret_file
        self.g_auth.settings["save_credentials_file"] = credentials_json
        self.g_auth.settings["save_credentials"] = True
        self.g_auth.settings["save_credentials_backend"] = "file"
        self.g_auth.settings["get_refresh_token"] = True
        self.g_auth.CommandLineAuth()
        self.googleDrive = GoogleDrive(self.g_auth)
        self.matchingRemotesCount = 0
        db_name = os.path.join(self.root_folder, GooglePhotosSync.DB_NAME)
        self.db = pickledb.load(db_name, False)

    def store_data(self):
        self.db.dump()

    def get_photos_folder_id(self):
        query_results = self.googleDrive.ListFile(
            {"q": GooglePhotosSync.GOOGLE_PHOTO_FOLDER_QUERY}).GetList()
        try:
            return query_results[0]["id"]
        except:
            raise NoGooglePhotosFolderError()

    def add_date_filter(self, query_params):
        if self.args.start_date:
            query_params[
                'q'] += GooglePhotosSync.AFTER_QUERY % self.args.start_date
        elif self.args.end_date:
            query_params[
                'q'] += GooglePhotosSync.BEFORE_QUERY % self.args.end_date

    def get_remote_folder(self, parent_id, folder_name):
        this_folder_id = None
        parts = folder_name.split('/', 1)
        query_params = {
            "q": GooglePhotosSync.FOLDER_QUERY % (parts[0], parent_id)
        }

        for results in self.googleDrive.ListFile(query_params):
            this_folder_id = results[0]["id"]
        if len(parts) > 1:
            this_folder_id = self.get_remote_folder(this_folder_id, parts[1])
        return this_folder_id

    def get_remote_medias(self, folder_id):
        query_params = {
            "q": GooglePhotosSync.MEDIA_QUERY % folder_id,
            "maxResults": GooglePhotosSync.PAGE_SIZE,
            # "orderBy": 'createdDate desc, title'
            "orderBy": 'title'
        }
        self.add_date_filter(query_params)

        for page_results in self.googleDrive.ListFile(query_params):
            for drive_file in page_results:
                if not self.args.include_video:
                    if drive_file["mimeType"].startswith("video/"):
                        continue
                media = GooglePhotosMedia(drive_file)
                yield media

    def get_remote_media_by_name(self, filename):
        google_photos_folder_id = self.get_photos_folder_id()
        query_params = {
            "q": 'title = "%s" and "%s" in parents and trashed=false' %
                 (filename, google_photos_folder_id)
        }
        found_media = self.googleDrive.ListFile(query_params).GetList()
        return GooglePhotosMedia(found_media[0]) if found_media else None

    def get_local_medias(self):
        for directory, _, files in os.walk(self.start_folder):
            for filename in files:
                media_path = os.path.join(directory, filename)
                mime_type, _ = mimetypes.guess_type(media_path)
                if mime_type and mime_type.startswith('image/'):
                    yield LocalMedia(media_path)

    # currently using remote folder structure so this is not used
    # but may require a rethink later
    def get_target_folder(self, media):
        year_month_folder = media.date.strftime("%Y/%m")
        target_folder = os.path.join(self.start_folder, year_month_folder)
        return target_folder

    def is_indexed(self, path, media):
        local_filename = os.path.join(path, media.filename)
        file_record = self.db.get(local_filename)
        if file_record:
            if file_record['id'] == media.id:
                return True
            else:
                media.duplicate_number += 1
                return self.is_indexed(path, media)
        return False

    def has_local_version(self, path, media):
        local_filename = os.path.join(path, media.filename)

        # recursively check if any existing duplicates have same id
        if os.path.isfile(local_filename):
            media_record = self.db.get(media.id)
            if media_record and media_record['filename'] == local_filename:
                return True
            else:
                media.duplicate_number += 1
                return self.has_local_version(path, media)
        return False

    def download_media(self, media, path, progress_handler=None):
        if not os.path.isdir(path):
            os.makedirs(path)

        target_filename = os.path.join(path, media.filename)
        temp_filename = os.path.join(path, '.temp-gphotos')

        if not self.args.index_only:
            # retry for occasional transient quota errors - http 503
            for retry in range(10):
                try:
                    with io.open(temp_filename, 'bw') as target_file:
                        request = self.g_auth.service.files().get_media(
                            fileId=media.id)
                        download_request = http.MediaIoBaseDownload(target_file,
                                                                    request)

                        done = False
                        while not done:
                            download_status, done = \
                                download_request.next_chunk()
                            if progress_handler is not None:
                                progress_handler.update_progress(
                                    download_status)
                except Exception as e:
                    print('\nRETRYING due to', e)
                    continue

                os.rename(temp_filename, target_filename)
                break

        # todo - root relative names here would make the folders portable
        # store meta data indexed by unique id
        self.db.dcreate(media.id)
        self.db.dadd(media.id, ('filename', target_filename))
        self.db.dadd(media.id, ('description', media.description))
        self.db.dadd(media.id, ('checksum', media.checksum))
        # reverse lookup by filename
        self.db.dcreate(target_filename)
        self.db.dadd(target_filename, ('id', media.id))
        return target_filename

    def upload_media(self, local_media, progress_handler=None):

        remote_media = self.get_remote_media_by_name(local_media.filename)

        media_body = MediaFileUpload(local_media.path, resumable=True)

        if remote_media:
            upload_request = self.g_auth.service.files().update(
                fileId=remote_media.id,
                body=remote_media.drive_file,
                newRevision=True,
                media_body=media_body)
        else:
            body = {
                'title': local_media.filename,
                'mimetype': local_media.mimetype
            }
            upload_request = self.g_auth.service.files().insert(
                body=body,
                media_body=media_body)

        done = False
        while not done:
            upload_status, done = upload_request.next_chunk()
            if progress_handler is not None:
                progress_handler.update_progress(upload_status)


class ProgressHandler(object):
    def __init__(self, media):

        progress_bar_widgets = [
            media.filename,
            "  ",
            Percentage(),
            Bar(),
            " ",
            AdaptiveTransferSpeed(),
            "  ",
            AdaptiveETA(),
        ]

        self.progress_bar = ProgressBar(maxval=media.size,
                                        term_width=80,
                                        widgets=progress_bar_widgets)
        self.progress_bar.start()

    def update_progress(self, status):
        if not status or status.progress() == 1:
            self.progress_bar.finish()

        else:
            size_downloaded = status.progress() * status.total_size
            self.progress_bar.update(size_downloaded)


###############################################################################
# Command functions
###############################################################################


def download_folder(folder_id, path, google_photos_sync, args):
    print('-------------------- %s' % path)
    progress_handler = None
    for remote_media in google_photos_sync.get_remote_medias(folder_id):

        if remote_media.drive_file.metadata[u'mimeType'].endswith('folder'):
            new_path = os.path.join(path, remote_media.filename)
            download_folder(remote_media.id, new_path, google_photos_sync, args)
        else:
            if args.index_only:
                if google_photos_sync.is_indexed(path, remote_media):
                    continue
            else:
                if google_photos_sync.has_local_version(path, remote_media):
                    continue

            if args.dry_run:
                print("Downloading %s" % remote_media.filename)
                continue

            if not (args.quiet or args.index_only):
                progress_handler = ProgressHandler(remote_media)

            google_photos_sync.download_media(remote_media, path,
                                              progress_handler=progress_handler)


def download_command(gs, args):
    folder_id = gs.get_photos_folder_id()

    if gs.start_folder != '.':
        folder_id = gs.get_remote_folder(folder_id, gs.start_folder)

    download_folder(folder_id, gs.target_folder, gs, args)


def re_upload_command(gs, args):
    progress_handler = None
    for local_media in gs.get_local_medias():

        remote_media = gs.get_remote_media_by_name(
            local_media.filename)

        if not remote_media or remote_media.checksum == local_media.checksum:
            continue

        if args.dry_run:
            print("Re-uploading %s" % remote_media.filename)
            continue

        if not args.quiet:
            progress_handler = ProgressHandler(local_media)

        gs.upload_media(local_media,
                        progress_handler=progress_handler)


###############################################################################
# Main code
###############################################################################

def parse_arguments():
    parser = argparse.ArgumentParser(
        description="Google Photos simple synchronization tool")
    parser.add_argument(
        "--quiet",
        action='store_true',
        help="quiet (no output)")
    parser.add_argument(
        "--dry-run",
        action='store_true',
        help="show what would have been transferred")
    parser.add_argument(
        "--include-video",
        action='store_true',
        help="include video types in sync")
    parser.add_argument(
        "command",
        choices=["re-upload", "download"],
        help="command to execute")
    parser.add_argument(
        "root_folder",
        help="root of the local folders to download into")
    parser.add_argument(
        "--start-folder",
        help="Google Photos folder to sync e.g. 2017/08, defaults to root",
        default='.')
    parser.add_argument(
        "--start-date",
        help="Set the earliest date of files to sync",
        default=None)
    parser.add_argument(
        "--end-date",
        help="Set the latest date of files to sync",
        default=None)
    parser.add_argument(
        "--new-token",
        action='store_true',
        help="Request new token")
    parser.add_argument(
        "--index-only",
        action='store_true',
        help="Only build the index of files in .gphotos.db - no downloads")
    return parser.parse_args()


def main():
    cmd_args = parse_arguments()
    app_dirs = AppDirs(APPNAME)

    credentials_file = os.path.join(app_dirs.user_data_dir, "credentials.json")
    secret_file = os.path.join(app_dirs.user_config_dir, "client_secret.json")

    google_photos_sync = GooglePhotosSync(cmd_args,
                                          client_secret_file=secret_file,
                                          credentials_json=credentials_file)

    # todo photo album metadata download code is under development
    # this code demonstrates how to use the already obtained oauth2 credentials
    # to connect to photos api with gdata. However :-
    # python gdata is out of date (at v1). Even the current v3 api in Java does
    # not appear to provide ability to create albums so some goals of this
    # project may be unobtainable. Shared albums are not seen by the API.

    try:
        # pi = PhotoInfo()
        # pi.connect_photos(google_photos_sync.g_auth.credentials)
        # pi.get_albums()

        if cmd_args.command == "download":
            download_command(google_photos_sync, cmd_args)

        elif cmd_args.command == "re-upload":
            re_upload_command(google_photos_sync, cmd_args)

    except (KeyboardInterrupt, SystemExit):
        print("\nUser cancelled download")
        with open(".gphoto-terminated", "w") as text_file:
            text_file.write(traceback.format_exc())
    finally:
        print("saving metadata ...")
        google_photos_sync.store_data()


if __name__ == "__main__":
    main()

# vim: autoindent tabstop=4 shiftwidth=4 expandtab softtabstop=4
